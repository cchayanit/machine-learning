{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('my_env': conda)",
   "metadata": {
    "interpreter": {
     "hash": "1349c69591972c57d67892a52a0774a8b2f0c050bac35893b43960f3926bbe0d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import codecs\n",
    "import numpy\n",
    "from pandas import DataFrame\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "source": [
    "# สร้าง data ด้วย pandas DataFrame"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [{'text':'London bridge is falling down','class':'london'}]\n",
    "d.append({'text':'japan samurai universal studio spider man','class':'japan'});\n",
    "d.append({'text':'china beijing','class':'china'});\n",
    "d.append({'text':'thai chiangmai','class':'thailand'});\n",
    "d.append({'text':'universal studio hollywood','class':'usa'});"
   ]
  },
  {
   "source": [
    "# convert เป็น DataFrame   ดึงมาเฉพาะ field text"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_text=data.iloc[:]['text'].values"
   ]
  },
  {
   "source": [
    "# CountVectorizer ทำ tokenize"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words='english', lowercase=True)"
   ]
  },
  {
   "source": [
    "# เริ่มตัดคำ"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = vect.fit(arr_text)"
   ]
  },
  {
   "source": [
    "# ดู vocabulary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'london': 7,\n",
       " 'bridge': 1,\n",
       " 'falling': 4,\n",
       " 'japan': 6,\n",
       " 'samurai': 9,\n",
       " 'universal': 13,\n",
       " 'studio': 11,\n",
       " 'spider': 10,\n",
       " 'man': 8,\n",
       " 'china': 3,\n",
       " 'beijing': 0,\n",
       " 'thai': 12,\n",
       " 'chiangmai': 2,\n",
       " 'hollywood': 5}"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "vect.vocabulary_"
   ]
  },
  {
   "source": [
    "# ทำ transform ให้อยู่ในรูปแบบ One Hot Encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = vect.transform(arr_text)"
   ]
  },
  {
   "source": [
    "# ดูผลลัพท์ matrix ที่ได้โดย array จะประกอบด้วย context ใน 1 paragraph หากมี word ใน context ให้ค่าเป็น 1 และหากไม่มี word ใน context ให้ค่าเป็น 0"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 1 0 0 1 0 0 1 0 0 0 0 0 0]\n [0 0 0 0 0 0 1 0 1 1 1 1 0 1]\n [1 0 0 1 0 0 0 0 0 0 0 0 0 0]\n [0 0 1 0 0 0 0 0 0 0 0 0 1 0]\n [0 0 0 0 0 1 0 0 0 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(transformer.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  (0, 1)\t1\n  (0, 4)\t1\n  (0, 7)\t1\n  (1, 6)\t1\n  (1, 8)\t1\n  (1, 9)\t1\n  (1, 10)\t1\n  (1, 11)\t1\n  (1, 13)\t1\n  (2, 0)\t1\n  (2, 3)\t1\n  (3, 2)\t1\n  (3, 12)\t1\n  (4, 5)\t1\n  (4, 11)\t1\n  (4, 13)\t1\n"
     ]
    }
   ],
   "source": [
    "print(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of Sparse Matrix:  (5, 14)\n"
     ]
    }
   ],
   "source": [
    "print ('Shape of Sparse Matrix: ', transformer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Amount of Non-Zero occurences:  16\n"
     ]
    }
   ],
   "source": [
    "print ('Amount of Non-Zero occurences: ', transformer.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sparsity: 22.86%\n"
     ]
    }
   ],
   "source": [
    "print ('sparsity: %.2f%%' % (100.0 * transformer.nnz /\n",
    "(transformer.shape[0] * transformer.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.47140452],\n",
       "       [0.        , 0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.47140452, 0.        , 0.        , 1.        ]])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(transformer)"
   ]
  },
  {
   "source": [
    "#จะเห็นว่า Document 1 และ 4 มีความเหมือนกันอยู่ที่ 0.471 โดยที่หากค่าเป็น 1 แสดงว่ามีความเหมือนมากที่สุดและ 0 คือไม่มีความเหมือนกันเลย (มีคำว่า Universal Studio เหมือนกัน)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Config tf-idf"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf=False,).fit(transformer)"
   ]
  },
  {
   "source": [
    "#show ค่า idf"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2.60943791, 2.60943791, 2.60943791, 2.60943791, 2.60943791,\n",
       "       2.60943791, 2.60943791, 2.60943791, 2.60943791, 2.60943791,\n",
       "       2.60943791, 1.91629073, 2.60943791, 1.91629073])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "tfidf_transformer.idf_"
   ]
  },
  {
   "source": [
    "#จะเห็นว่าซ้ำกัน 2 คำคือ universal และ studio ที่เหลือไม่ซ้ำกันมีค่า 2.6\n",
    "จะมี 2 คำคือคำว่า Universal และ Studio ที่มีค่าน้อยกว่า IDF แสดงให้เห็นว่าสองคำนี้มีความเป็น Unique น้อยกว่าเพราะมีการใช้ซ้ำใน Context อื่น"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#tf(t) = จำนวนที่ปรากฏใน document/จำนวนคำทั้งหมดใน document\n",
    "#idf(d, t) = ln(จำนวน document ทั้งหมด/จำนวนที่ปรากฏใน Document) + 1\n",
    "#idf(d, t) = ln [ (1 + จำนวน document) / (1 + จำนวนที่ปรากฏใน Document) ] + 1\n",
    "#Parameter smoot=true => ln((1+5)/(1+1))+1 = 2.09861229\n",
    "#Parameter smoot=false=>ln(5)+1 = 2.60943791\n",
    "#บางนิยามใช้ log() บางนิยามใช้ ln()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "source": [
    "# เตรียม Class ในรูปแบบ array เหมือน arr_text"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['london', 'japan', 'china', 'thailand', 'usa'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "arr_class=data.iloc[:]['class'].values\n",
    "arr_class"
   ]
  },
  {
   "source": [
    "# เตรียม train จาก transformer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_tfidf = tfidf_transformer.transform(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5, 14)\n"
     ]
    }
   ],
   "source": [
    "print (messages_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.        , 0.57735027, 0.        , 0.        , 0.57735027,\n",
       "        0.        , 0.        , 0.57735027, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.44373957, 0.        , 0.44373957, 0.44373957,\n",
       "        0.44373957, 0.32586866, 0.        , 0.32586866],\n",
       "       [0.70710678, 0.        , 0.        , 0.70710678, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.70710678, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.70710678, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.69360936, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.50936532, 0.        , 0.50936532]])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "messages_tfidf.toarray()"
   ]
  },
  {
   "source": [
    "# สร้าง Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_model = MultinomialNB().fit(messages_tfidf,arr_class)"
   ]
  },
  {
   "source": [
    "# การ Predict\n",
    "สร้าง ตัว test\n",
    "จะ test ด้วยคำว่า london bridge is falling down"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'London bridge is falling down'"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "arr_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0=vect.transform([arr_text[0]])"
   ]
  },
  {
   "source": [
    "#แปลงเป็น vector"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "t0.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  (0, 1)\t1\n  (0, 4)\t1\n  (0, 7)\t1\n"
     ]
    }
   ],
   "source": [
    "print(t0)"
   ]
  },
  {
   "source": [
    "#นำ data ทั้งหมดที่ train ไป test มันก็ควรจะตรง(Expected คือ 100%)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = detect_model.predict(messages_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['london' 'japan' 'china' 'thailand' 'usa']\n"
     ]
    }
   ],
   "source": [
    "print(all_predictions)"
   ]
  },
  {
   "source": [
    "# ดูค่า Performance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n       china       1.00      1.00      1.00         1\n       japan       1.00      1.00      1.00         1\n      london       1.00      1.00      1.00         1\n    thailand       1.00      1.00      1.00         1\n         usa       1.00      1.00      1.00         1\n\n    accuracy                           1.00         5\n   macro avg       1.00      1.00      1.00         5\nweighted avg       1.00      1.00      1.00         5\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(arr_class, all_predictions))"
   ]
  },
  {
   "source": [
    "# ลอง test ด้วยคำใหม่ "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "thaitest = 'Hello chiangmai I am siam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectmp = vect.transform([thaitest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "vectmp.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tftmp = tfidf_transformer.transform(vectmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  (0, 2)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(tftmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['thailand'], dtype='<U8')"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "detect_model.predict(tftmp)"
   ]
  },
  {
   "source": [
    "# result"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['thailand'], dtype='<U8')"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "thaitest = 'Hello chiangmai I am siam'\n",
    "vectmp = vect.transform([thaitest])\n",
    "tftmp = tfidf_transformer.transform(vectmp)\n",
    "detect_model.predict(tftmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['china'], dtype='<U8')"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "thaitest = 'Wellcome to beijing'\n",
    "vectmp = vect.transform([thaitest])\n",
    "tftmp = tfidf_transformer.transform(vectmp)\n",
    "detect_model.predict(tftmp)\n"
   ]
  },
  {
   "source": [
    "###Save model to file\n",
    "\n",
    "#>>>> import pickle\n",
    "#>>>> pickle.dump(detect_model,open(\"/tmp/nb.md\",'wb'))\n",
    "\n",
    "###Load model from file\n",
    "\n",
    "#>>> import pickle\n",
    "#>>> nb_model = pickle.load(open('/tmp/nb.md','rb'))\n",
    "#>>> nb_model\n",
    "#MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}